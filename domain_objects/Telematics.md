# Data Science &amp; Telematics

### What is Telematics?

TELEMATICS is a method of monitoring an asset (car, truck, heavy equipment or even ship) by using GPS and onboard diagnostics to record movements on a computerized map. This information from the vehicle like speed, idling, fuel usage, tire pressure etc. can mean saving on maintenance cost by better monitoring vehicles or improving fuel efficiency by learning more about driving habits. All of this describes the universe of telematics, also known as GPS fleet tracking.

### How Telematics works and what is the role of Data Science?

To track assets, information from the vehicle is recorded via a small, telematics device — also called a black box —  that plugs into the [OBD II](https://www.geotab.com/blog/obd-ii/) or CAN-BUS port. A SIM card and modem in the device enables communication on the cellular network.

 Data collected by the telematics device, like the GPS position and speed of the vehicle, and the [g-force](https://www.geotab.com/blog/what-is-g-force/) measured by the built-in accelerometer, are sent in a packaged format to a data center. The data then gets decoded.

 A vast amount of data can be collected via the telematics device and other connected hardware or sensors, such as position, speed, trip distance/time, idling, harsh braking and driving, seat belt, fuel consumption, vehicle faults, battery voltage, and other engine data.

 There are several TSPs (Telematics Service Providers) who capture this information and store in the cloud or other data storage solutions. Data can then be brought into a fleet management software system, accessible from a desktop computer or a mobile device like a smartphone or tablet. Using the software, users are able to view and export reports and gain business intelligence such as the top 10 drivers with the highest number of speeding incidents or vehicles that are due for scheduled maintenance.

The telematics companies have access to a large amount of data that, with the help of data analytics, can be extremely useful in understanding metric trends from real time data feeds. And since the volume data is huge and every increasing, proper management becomes essential which warrants usage of data science and machine learning technologies for predictive analysis and even setting up Big Data ecosystems.

### What skills do I need?

- **Domain Knowledge:** Domain knowledge forms an essential ingredient for a data scientist to make effective use of data. It can be best gained on the job which is a long and intensive process. Reading and research on telematics related topics can also help in augmenting the learning process.
- **Presentation and Communication:** Effective representation and communication of the work done is essential to realize the full potential and recognition of the work done.
- **Data Engineering:** Data is available in different forms and sources. One should be able to design and build pipelines that transform and transport data into a format that is highly usable for various algorithms that will use it to make inferences.
- **Data Visualization:** Various python-based libraries are available that can be used build beautiful visualizations. However, various tools also available like Tableau, Amazon QuickSight and PowerBI which provide easy integration with different data sources like csv data files, databases, APIs etc to make various types of visualizations for analytics. These visualizations could easily be integrated into web applications and dashboards for sharing with different users.
- **General Statistics:** General understanding of statistics is needed to process complex problems in the real world to look for meaningful trends and changes in data.
- **Time series:** Given that telematics is time-series data, the problems are formulated as a time series prediction tasks to exploit the embedded sequential information. The robustness of the model on noisy and anomalous data is also investigated. Conclusions are derived based on variations in sequential data.
- **Machine Learning:** Machine learning is increasingly being applied to leverage availability of massive datasets and cheap compute power. Machine learning uses learning techniques to allow computers to learn from data without programming explicit rules.

### What specific tools should I focus on learning?

- Python
- Python libraries for Data Science - Pandas, Numpy, Scipy, Scikit-learn
- Python libraries for Visualization – Matplotlib, Plotly, Seaborn, GGPlot, Altair
- Python libraries for Machine Learning - Keras, PyTorch, XGBoost, TensorFlow
- Visualization Tools like Tableau, Amazon QuickSight, Power BI (Atleast one)
- R
- Statistics
- Jupyter Notebooks
- SQL
- Basic knowledge of some cloud related technologies for Data Science (Analytics and Machine Learning) like Amazon SageMaker is helpful.

Related Career Journeys

- Tarun Rawat

Last Updated: 11/12/2020
